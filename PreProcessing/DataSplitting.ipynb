{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os \n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "parentDir = os.path.dirname( cwd )\n",
    "sys.path.append(parentDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete. Train set: 130 files, Test set: 23 files.\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(data_dir=\"data/labeled/cloud\", train_dir=\"data/labeled/trainset\", test_dir=\"data/labeled/testset\", test_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset in `data_dir` into training and testing sets and copies them into `train_dir` and `test_dir`.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Directory containing the .npy files.\n",
    "        train_dir (str): Directory where the training set will be stored.\n",
    "        test_dir (str): Directory where the test set will be stored.\n",
    "        test_size (float): Proportion of the dataset to include in the test split.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    # Ensure directories exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Get all .npy files in the data directory\n",
    "    files = [f for f in os.listdir(data_dir) if f.endswith('.npy')]\n",
    "\n",
    "    # Split into train and test sets\n",
    "    train_files, test_files = train_test_split(files, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Copy files to their respective directories\n",
    "    for f in train_files:\n",
    "        shutil.copy(os.path.join(data_dir, f), os.path.join(train_dir, f))\n",
    "    for f in test_files:\n",
    "        shutil.copy(os.path.join(data_dir, f), os.path.join(test_dir, f))\n",
    "\n",
    "    print(f\"Dataset split complete. Train set: {len(train_files)} files, Test set: {len(test_files)} files.\")\n",
    "\n",
    "# Example usage\n",
    "\n",
    "data_dir = os.path.join( parentDir, 'data', 'labeled', 'cloud' )\n",
    "train_dir = os.path.join( parentDir, 'data', 'labeled', 'trainset' )\n",
    "test_dir = os.path.join( parentDir, 'data', 'labeled', 'testset' )\n",
    "\n",
    "split_dataset( data_dir, train_dir, test_dir )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TreeLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
